{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjjZ83VIXvGS",
        "outputId": "efbf7eb9-5fc3-4da9-958d-85d3f62bf5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -qq\n",
        "!pip install pylabel -qq\n",
        "!pip install lxml tqdm -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uVQmp83X9X9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c3e71a-8525-41b0-87c8-e9c011038bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os, random, cv2, json, shutil, yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import ultralytics\n",
        "\n",
        "from google.colab import drive\n",
        "from ultralytics import YOLO\n",
        "from pylabel import importer\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPHUp5_mYA_K",
        "outputId": "abc23f8f-4fcc-4c9a-dacd-e3f12e70b945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rWg--YIvXLn"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import json\n",
        "# from collections import defaultdict\n",
        "# from PIL import Image\n",
        "\n",
        "# # ========== EDIT THESE PATHS ==========\n",
        "# # JSONs\n",
        "# train_json = \"/content/drive/MyDrive/COCO2017/annotations/filtered_train2017.json\"\n",
        "# val_json   = \"/content/drive/MyDrive/COCO2017/annotations/filtered_val2017.json\"\n",
        "\n",
        "# # lists (one filename per line, basename or path)\n",
        "# train_list_path = \"/content/drive/MyDrive/COCO_FILTERD/txt/train_images.txt\"\n",
        "# val_list_path   = \"/content/drive/MyDrive/COCO_FILTERD/txt/val_images.txt\"\n",
        "\n",
        "# # image folders\n",
        "# train_images_dir = \"/content/drive/MyDrive/COCO_FILTERD/images/train\"\n",
        "# val_images_dir   = \"/content/drive/MyDrive/COCO_FILTERD/images/val\"\n",
        "\n",
        "# # output label folders (will contain /labels subfolder)\n",
        "# out_root_train = \"/content/drive/MyDrive/COCO_FILTERD/labels/train\"\n",
        "# out_root_val   = \"/content/drive/MyDrive/COCO_FILTERD/labels/val\"\n",
        "\n",
        "# # shared mapping output (we save it under a common parent)\n",
        "# mapping_out_dir = \"/content/drive/MyDrive/COCO_FILTERD/labels\"  # will contain coco_to_yolo.json, yolo_to_coco.json, names.txt\n",
        "# mapping_path = os.path.join(mapping_out_dir, \"coco_to_yolo.json\")\n",
        "# # ======================================\n",
        "\n",
        "# os.makedirs(out_root_train, exist_ok=True)\n",
        "# os.makedirs(out_root_val, exist_ok=True)\n",
        "# os.makedirs(mapping_out_dir, exist_ok=True)\n",
        "\n",
        "# def load_list(path):\n",
        "#     if not path or not os.path.exists(path):\n",
        "#         return []\n",
        "#     items = []\n",
        "#     with open(path, \"r\") as f:\n",
        "#         for line in f:\n",
        "#             s = line.strip()\n",
        "#             if s:\n",
        "#                 items.append(os.path.basename(s))\n",
        "#     return items\n",
        "\n",
        "# def load_coco(path):\n",
        "#     if not path or not os.path.exists(path):\n",
        "#         return {\"images\": [], \"annotations\": [], \"categories\": []}\n",
        "#     with open(path, \"r\") as f:\n",
        "#         return json.load(f)\n",
        "\n",
        "# def build_or_load_mapping(coco_list, mapping_path, mapping_out_dir):\n",
        "#     # try load existing mapping\n",
        "#     if os.path.exists(mapping_path):\n",
        "#         try:\n",
        "#             with open(mapping_path, \"r\") as f:\n",
        "#                 coco_to_yolo = json.load(f)\n",
        "#             print(\"Loaded existing mapping:\", mapping_path)\n",
        "#             return coco_to_yolo, None, None\n",
        "#         except Exception as e:\n",
        "#             print(\"Failed to load mapping, will rebuild. Error:\", e)\n",
        "\n",
        "#     # build mapping from union of categories across provided cocos\n",
        "#     cats_union = {}\n",
        "#     for coco in coco_list:\n",
        "#         for c in coco.get(\"categories\", []):\n",
        "#             cats_union[c[\"id\"]] = c[\"name\"]\n",
        "\n",
        "#     # sort by category id for stability\n",
        "#     cats_sorted = sorted(cats_union.items(), key=lambda x: int(x[0]))\n",
        "\n",
        "#     coco_to_yolo = {}\n",
        "#     yolo_to_coco = {}\n",
        "#     names = []\n",
        "#     for new_idx, (cid, name) in enumerate(cats_sorted):\n",
        "#         coco_to_yolo[str(cid)] = new_idx\n",
        "#         yolo_to_coco[str(new_idx)] = int(cid)\n",
        "#         names.append(name)\n",
        "\n",
        "#     # save mapping + names\n",
        "#     with open(os.path.join(mapping_out_dir, \"coco_to_yolo.json\"), \"w\") as f:\n",
        "#         json.dump(coco_to_yolo, f, indent=2)\n",
        "#     with open(os.path.join(mapping_out_dir, \"yolo_to_coco.json\"), \"w\") as f:\n",
        "#         json.dump(yolo_to_coco, f, indent=2)\n",
        "#     with open(os.path.join(mapping_out_dir, \"names.txt\"), \"w\") as f:\n",
        "#         f.write(\"\\n\".join(names))\n",
        "\n",
        "#     print(f\"Built mapping with {len(names)} categories and saved under {mapping_out_dir}\")\n",
        "#     return coco_to_yolo, yolo_to_coco, names\n",
        "\n",
        "# def generate_labels_for_list(coco, fname_to_id, anns_by_img, names_map, coco_to_yolo, images_dir, list_names, labels_out_dir, missing_json_list_path, missing_image_list_path):\n",
        "#     os.makedirs(labels_out_dir, exist_ok=True)\n",
        "#     written = 0\n",
        "#     missing_in_json = []\n",
        "#     missing_image_file = []\n",
        "\n",
        "#     for fname in list_names:\n",
        "#         base = os.path.splitext(fname)[0]\n",
        "#         out_path = os.path.join(labels_out_dir, base + \".txt\")\n",
        "\n",
        "#         if fname not in fname_to_id:\n",
        "#             missing_in_json.append(fname)\n",
        "#             open(out_path, \"w\").close()\n",
        "#             continue\n",
        "\n",
        "#         img_id = fname_to_id[fname]\n",
        "#         iminfo = coco[\"images_by_id\"].get(img_id)\n",
        "#         if iminfo is None:\n",
        "#             missing_in_json.append(fname)\n",
        "#             open(out_path, \"w\").close()\n",
        "#             continue\n",
        "\n",
        "#         W = iminfo.get(\"width\")\n",
        "#         H = iminfo.get(\"height\")\n",
        "\n",
        "#         # try to get size from disk if missing\n",
        "#         if (W is None or H is None):\n",
        "#             img_path = os.path.join(images_dir, fname)\n",
        "#             if os.path.exists(img_path):\n",
        "#                 try:\n",
        "#                     with Image.open(img_path) as im:\n",
        "#                         W, H = im.size\n",
        "#                 except Exception:\n",
        "#                     missing_image_file.append(fname)\n",
        "#                     open(out_path, \"w\").close()\n",
        "#                     continue\n",
        "#             else:\n",
        "#                 missing_image_file.append(fname)\n",
        "#                 open(out_path, \"w\").close()\n",
        "#                 continue\n",
        "\n",
        "#         lines = []\n",
        "#         for ann in anns_by_img.get(img_id, []):\n",
        "#             x, y, w, h = ann[\"bbox\"]\n",
        "#             if w <= 0 or h <= 0:\n",
        "#                 continue\n",
        "#             coco_cat = ann[\"category_id\"]\n",
        "#             if str(coco_cat) in coco_to_yolo:\n",
        "#                 cls = int(coco_to_yolo[str(coco_cat)])\n",
        "#             else:\n",
        "#                 cls = int(coco_cat)\n",
        "#             cx = (x + w/2) / float(W)\n",
        "#             cy = (y + h/2) / float(H)\n",
        "#             wn = w / float(W)\n",
        "#             hn = h / float(H)\n",
        "#             # clamp\n",
        "#             cx = max(0.0, min(1.0, cx))\n",
        "#             cy = max(0.0, min(1.0, cy))\n",
        "#             wn = max(0.0, min(1.0, wn))\n",
        "#             hn = max(0.0, min(1.0, hn))\n",
        "#             lines.append(f\"{cls} {cx:.6f} {cy:.6f} {wn:.6f} {hn:.6f}\")\n",
        "\n",
        "#         with open(out_path, \"w\") as f:\n",
        "#             f.write(\"\\n\".join(lines))\n",
        "#         written += 1\n",
        "\n",
        "#     # save missing lists\n",
        "#     if missing_in_json and missing_json_list_path:\n",
        "#         with open(missing_json_list_path, \"w\") as f:\n",
        "#             for n in missing_in_json:\n",
        "#                 f.write(n + \"\\n\")\n",
        "#     if missing_image_file and missing_image_list_path:\n",
        "#         with open(missing_image_list_path, \"w\") as f:\n",
        "#             for n in missing_image_file:\n",
        "#                 f.write(n + \"\\n\")\n",
        "\n",
        "#     return written, missing_in_json, missing_image_file\n",
        "\n",
        "# # -------- Load lists ----------\n",
        "# train_names = load_list(train_list_path)\n",
        "# val_names = load_list(val_list_path)\n",
        "\n",
        "# print(f\"Train list: {len(train_names)} entries (unique {len(set(train_names))})\")\n",
        "# print(f\"Val list:   {len(val_names)} entries (unique {len(set(val_names))})\")\n",
        "\n",
        "# # -------- Load COCO JSONs ----------\n",
        "# train_coco = load_coco(train_json)\n",
        "# val_coco   = load_coco(val_json)\n",
        "\n",
        "# # Build quick maps for train and val\n",
        "# def prepare_coco_maps(coco):\n",
        "#     images = coco.get(\"images\", [])\n",
        "#     anns = coco.get(\"annotations\", [])\n",
        "#     images_by_id = {im[\"id\"]: im for im in images}\n",
        "#     fname_to_id = {os.path.basename(im[\"file_name\"]): im[\"id\"] for im in images}\n",
        "#     anns_by_img = defaultdict(list)\n",
        "#     for ann in anns:\n",
        "#         anns_by_img[ann[\"image_id\"]].append(ann)\n",
        "#     coco[\"images_by_id\"] = images_by_id\n",
        "#     coco[\"fname_to_id\"] = fname_to_id\n",
        "#     coco[\"anns_by_img\"] = anns_by_img\n",
        "\n",
        "# prepare_coco_maps(train_coco)\n",
        "# prepare_coco_maps(val_coco)\n",
        "\n",
        "# # -------- Build or load mapping from union of categories ----------\n",
        "# coco_to_yolo, yolo_to_coco, names = build_or_load_mapping([train_coco, val_coco], mapping_path, mapping_out_dir)\n",
        "\n",
        "# # if build_or_load returned only coco_to_yolo (when loaded), attempt to also build names from json(s)\n",
        "# if names is None:\n",
        "#     # try to collect category names from train then val\n",
        "#     cats = train_coco.get(\"categories\", []) or val_coco.get(\"categories\", [])\n",
        "#     cats_sorted = sorted(cats, key=lambda c: c[\"id\"]) if cats else []\n",
        "#     names = [c[\"name\"] for c in cats_sorted] if cats_sorted else []\n",
        "\n",
        "# # -------- Generate labels for train ----------\n",
        "# written_train, missing_train_json, missing_train_image = generate_labels_for_list(\n",
        "#     train_coco,\n",
        "#     train_coco[\"fname_to_id\"],\n",
        "#     train_coco[\"anns_by_img\"],\n",
        "#     names,\n",
        "#     coco_to_yolo,\n",
        "#     train_images_dir,\n",
        "#     train_names,\n",
        "#     os.path.join(out_root_train, \"labels\"),\n",
        "#     os.path.join(out_root_train, \"missing_in_json.txt\"),\n",
        "#     os.path.join(out_root_train, \"missing_image_files.txt\")\n",
        "# )\n",
        "\n",
        "# print(f\"\\nTrain: Written {written_train} labels to {os.path.join(out_root_train, 'labels')}\")\n",
        "# if missing_train_json:\n",
        "#     print(f\"Train: {len(missing_train_json)} images in train_list not found in train.json (sample): {missing_train_json[:10]}\")\n",
        "# if missing_train_image:\n",
        "#     print(f\"Train: {len(missing_train_image)} train images missing on disk or unreadable (sample): {missing_train_image[:10]}\")\n",
        "\n",
        "# # -------- Generate labels for val ----------\n",
        "# written_val, missing_val_json, missing_val_image = generate_labels_for_list(\n",
        "#     val_coco,\n",
        "#     val_coco[\"fname_to_id\"],\n",
        "#     val_coco[\"anns_by_img\"],\n",
        "#     names,\n",
        "#     coco_to_yolo,\n",
        "#     val_images_dir,\n",
        "#     val_names,\n",
        "#     os.path.join(out_root_val, \"labels\"),\n",
        "#     os.path.join(out_root_val, \"missing_in_json.txt\"),\n",
        "#     os.path.join(out_root_val, \"missing_image_files.txt\")\n",
        "# )\n",
        "\n",
        "# print(f\"\\nVal: Written {written_val} labels to {os.path.join(out_root_val, 'labels')}\")\n",
        "# if missing_val_json:\n",
        "#     print(f\"Val: {len(missing_val_json)} images in val_list not found in val.json (sample): {missing_val_json[:10]}\")\n",
        "# if missing_val_image:\n",
        "#     print(f\"Val: {len(missing_val_image)} val images missing on disk or unreadable (sample): {missing_val_image[:10]}\")\n",
        "\n",
        "# print(\"\\nAll done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFpB6rmqv1Fk"
      },
      "outputs": [],
      "source": [
        "# output_path = \"/content/drive/MyDrive/COCO_FILTERD/data.yaml\"\n",
        "# root_path   = \"/content/drive/MyDrive/COCO_FILTERD\"\n",
        "\n",
        "# classes = [\"person\",\"chair\",\"car\",\"dining table\",\"cup\",\"bottle\",\"bowl\",\"handbag\",\"truck\",\"bench\",\"backpack\",\"book\",\n",
        "#            \"cell phone\",\"tv\",\"couch\",\"dog\",\"knife\",\"sports ball\",\"traffic light\",\"cat\",\"umbrella\",\"bus\",\"bed\",\"train\",\n",
        "#            \"fork\",\"spoon\",\"laptop\",\"motorcycle\",\"bicycle\",\"sandwich\",\"banana\",\"stop sign\",\"orange\",\"carrot\",\"apple\"\n",
        "#            ]\n",
        "\n",
        "# data_yaml = {\n",
        "#     \"path\": root_path,\n",
        "#     \"train\": \"images/train\",\n",
        "#     \"val\": \"images/val\",\n",
        "#     \"nc\": len(classes),\n",
        "#     \"names\": classes\n",
        "# }\n",
        "\n",
        "# with open(output_path, \"w\") as f:\n",
        "#     yaml.dump(data_yaml, f, sort_keys=False)\n",
        "\n",
        "# print(\"data.yaml created at:\", output_path)\n",
        "# print(\"Number of classes =\", len(classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZA9umTeGzyK",
        "outputId": "b31843f4-9982-4c0d-9186-810253369f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== TRAIN =====\n",
            "train lenth: 59637\n"
          ]
        }
      ],
      "source": [
        "root = \"/content/drive/MyDrive/COCO_FILTERD\"\n",
        "\n",
        "train_images = os.path.join(root, \"images/train\")\n",
        "train_labels = os.path.join(root, \"labels/train\")\n",
        "\n",
        "val_images = os.path.join(root, \"images/val\")\n",
        "val_labels = os.path.join(root, \"labels/val\")\n",
        "\n",
        "def count_files(folder, exts):\n",
        "    if not os.path.exists(folder):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(folder) if f.lower().endswith(exts)])\n",
        "\n",
        "img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "print(\"===== TRAIN =====\")\n",
        "print(\"train lenth:\", count_files(train_images, img_exts))\n",
        "print(\"labels train lenth:\", count_files(train_labels, (\".txt\",)))\n",
        "\n",
        "print(\"\\n===== VAL =====\")\n",
        "print(\"val lenth:\", count_files(val_images, img_exts))\n",
        "print(\"labels val lenth:\", count_files(val_labels, (\".txt\",)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hr1bDwMK6diQ",
        "outputId": "510eb4fe-8b8e-4226-8829-870e43853fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Your Eyes - YOLO Model Training\n",
            "======================================================================\n",
            "\n",
            "üì¶ Base model: yolov8n.pt\n",
            "üìä Dataset config: /content/drive/MyDrive/COCO_FILTERD/data.yaml\n",
            "üîÑ Epochs: 50\n",
            "üìè Batch size: 16\n",
            "üñºÔ∏è  Image size: 640\n",
            "üìÅ Project name: youreyes_model\n",
            "üìÇ Save dir: /content/drive/MyDrive/COCO_FILTERD/saved_models\n",
            "\n",
            "Loading base model...\n",
            "üöÄ Starting training...\n",
            "======================================================================\n",
            "\n",
            "Ultralytics 8.3.229 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/COCO_FILTERD/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=youreyes_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/COCO_FILTERD/saved_models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/COCO_FILTERD/saved_models/youreyes_model, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=35\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    758137  ultralytics.nn.modules.head.Detect           [35, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,017,673 parameters, 3,017,657 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.5¬±0.1 ms, read: 0.3¬±0.1 MB/s, size: 192.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/COCO_FILTERD/labels/train...: 0% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0/59637  1:53\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset_cache_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# attempt to load a *.cache file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDATASET_CACHE_VERSION\u001b[0m  \u001b[0;31m# matches current version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mload_dataset_cache_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reduce pickle load time https://github.com/ultralytics/ultralytics/pull/1585\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/COCO_FILTERD/labels/train.cache'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-418723589.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         train_youreyes_model(\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0mmodel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mdata_yaml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-418723589.py\u001b[0m in \u001b[0;36mtrain_youreyes_model\u001b[0;34m(model_size, data_yaml, epochs, batch_size, img_size, project_name, resume, save_dir)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         self.train_loader = self.get_dataloader(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Mode must be 'train' or 'val', not {mode}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m     76\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;34m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLOMultiModalDataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmulti_modal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mYOLODataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     return dataset(\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Can not use both segments and keypoints.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"channels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./labels.cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mni\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mget_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# identical hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# run cache ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Display cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36mcache_labels\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    122\u001b[0m             )\n\u001b[1;32m    123\u001b[0m             \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTQDM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mim_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnm_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mnm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnm_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mnf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnf_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# ---------- CUSTOM PATHS ----------\n",
        "DEFAULT_DATA_YAML = \"/content/drive/MyDrive/COCO_FILTERD/data.yaml\"\n",
        "DEFAULT_SAVE_DIR = \"/content/drive/MyDrive/COCO_FILTERD/saved_models\"\n",
        "# -----------------------------------\n",
        "\n",
        "\n",
        "def train_youreyes_model(\n",
        "    model_size: str = \"n\",\n",
        "    data_yaml: str = DEFAULT_DATA_YAML,\n",
        "    epochs: int = 50,\n",
        "    batch_size: int = 16,\n",
        "    img_size: int = 640,\n",
        "    project_name: str = \"youreyes_model\",\n",
        "    resume: bool = False,\n",
        "    save_dir: str = DEFAULT_SAVE_DIR,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train YOLO model on Your Eyes dataset\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Your Eyes - YOLO Model Training\")\n",
        "    print(\"=\" * 70)\n",
        "    print()\n",
        "\n",
        "    # Validate data.yaml exists\n",
        "    if not Path(data_yaml).exists():\n",
        "        print(f\"‚ùå Error: {data_yaml} not found!\")\n",
        "        print(\"Please create data.yaml with your dataset configuration\")\n",
        "        return\n",
        "\n",
        "    # Select base model\n",
        "    model_name = f\"yolov8{model_size}.pt\"\n",
        "    print(f\"üì¶ Base model: {model_name}\")\n",
        "    print(f\"üìä Dataset config: {data_yaml}\")\n",
        "    print(f\"üîÑ Epochs: {epochs}\")\n",
        "    print(f\"üìè Batch size: {batch_size}\")\n",
        "    print(f\"üñºÔ∏è  Image size: {img_size}\")\n",
        "    print(f\"üìÅ Project name: {project_name}\")\n",
        "    print(f\"üìÇ Save dir: {save_dir}\")\n",
        "    print()\n",
        "\n",
        "    # Load model\n",
        "    print(\"Loading base model...\")\n",
        "    model = YOLO(model_name)\n",
        "\n",
        "    # Create save dir path if not exists\n",
        "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Training parameters\n",
        "    train_args = {\n",
        "        \"data\": data_yaml,\n",
        "        \"epochs\": epochs,\n",
        "        \"imgsz\": img_size,\n",
        "        \"batch\": batch_size,\n",
        "        \"name\": project_name,\n",
        "        \"project\": save_dir,\n",
        "        \"exist_ok\": True,\n",
        "        \"patience\": 10,\n",
        "        \"save\": True,\n",
        "        \"save_period\": 10,\n",
        "        \"cache\": False,\n",
        "        \"device\": 0,\n",
        "        \"workers\": 8,\n",
        "        \"pretrained\": True,\n",
        "        \"optimizer\": \"auto\",\n",
        "        \"verbose\": True,\n",
        "        \"seed\": 42,\n",
        "        \"deterministic\": True,\n",
        "        \"single_cls\": False,\n",
        "        \"rect\": False,\n",
        "        \"cos_lr\": False,\n",
        "        \"close_mosaic\": 10,\n",
        "        \"resume\": resume,\n",
        "        \"amp\": True,\n",
        "        \"fraction\": 1.0,\n",
        "        \"profile\": False,\n",
        "        \"overlap_mask\": True,\n",
        "        \"mask_ratio\": 4,\n",
        "        \"dropout\": 0.0,\n",
        "        \"val\": True,\n",
        "        \"plots\": True,\n",
        "    }\n",
        "\n",
        "    print(\"üöÄ Starting training...\")\n",
        "    print(\"=\" * 70)\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        results = model.train(**train_args)\n",
        "\n",
        "        print()\n",
        "        print(\"=\" * 70)\n",
        "        print(\"‚úÖ Training completed successfully!\")\n",
        "        print(\"=\" * 70)\n",
        "        print()\n",
        "\n",
        "        run_folder = Path(save_dir) / project_name\n",
        "        print(f\"üìÅ Results saved to: {run_folder}\")\n",
        "        print(f\"üèÜ Best model: {run_folder}/weights/best.pt\")\n",
        "        print(f\"üìä Last model: {run_folder}/weights/last.pt\")\n",
        "        print()\n",
        "        print(\"To use your trained model:\")\n",
        "        print(\"1. In the app, go to Settings\")\n",
        "        print(f\"2. Set model path to: {run_folder}/weights/best.pt\")\n",
        "        print(\"3. Click 'Load/Reload Model'\")\n",
        "        print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print()\n",
        "        print(\"=\" * 70)\n",
        "        print(f\"‚ùå Training failed: {e}\")\n",
        "        print(\"=\" * 70)\n",
        "        print()\n",
        "\n",
        "\n",
        "def validate_model(model_path: str, data_yaml: str = DEFAULT_DATA_YAML):\n",
        "    \"\"\"\n",
        "    Validate trained model on validation set\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"Validating Model\")\n",
        "    print(\"=\" * 70)\n",
        "    print()\n",
        "\n",
        "    model = YOLO(model_path)\n",
        "    results = model.val(data=data_yaml)\n",
        "\n",
        "    print()\n",
        "    print(\"Validation Results:\")\n",
        "    # depending on ultralytics version the attribute names can vary; guard for missing attrs\n",
        "    try:\n",
        "        print(f\"mAP50: {results.box.map50:.4f}\")\n",
        "    except Exception:\n",
        "        print(\"mAP50: (attribute not found in results)\")\n",
        "\n",
        "    try:\n",
        "        print(f\"mAP50-95: {results.box.map:.4f}\")\n",
        "    except Exception:\n",
        "        print(\"mAP50-95: (attribute not found in results)\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def build_arg_parser():\n",
        "    parser = argparse.ArgumentParser(description=\"Train Your Eyes YOLO model\")\n",
        "\n",
        "    parser.add_argument(\"--model\", type=str, default=\"n\", choices=[\"n\", \"s\", \"m\", \"l\", \"x\"])\n",
        "    parser.add_argument(\"--data\", type=str, default=DEFAULT_DATA_YAML, help=\"Path to data.yaml\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=50)\n",
        "    parser.add_argument(\"--batch\", type=int, default=16)\n",
        "    parser.add_argument(\"--img-size\", type=int, default=640)\n",
        "    parser.add_argument(\"--name\", type=str, default=\"youreyes_model\")\n",
        "    parser.add_argument(\"--resume\", action=\"store_true\")\n",
        "    parser.add_argument(\"--validate\", type=str, help=\"Validate a trained model (provide path to weights)\")\n",
        "    parser.add_argument(\"--save-dir\", type=str, default=DEFAULT_SAVE_DIR, help=\"Directory to save training runs\")\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = build_arg_parser()\n",
        "\n",
        "    # -------------------------\n",
        "    # NOTE: use parse_known_args() to avoid Jupyter/Colab kernel args errors.\n",
        "    # This will work both in notebooks and when you run as a script.\n",
        "    # -------------------------\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    # You can inspect unknown if you want: print(\"Ignored args:\", unknown)\n",
        "\n",
        "    if args.validate:\n",
        "        validate_model(args.validate, args.data)\n",
        "    else:\n",
        "        train_youreyes_model(\n",
        "            model_size=args.model,\n",
        "            data_yaml=args.data,\n",
        "            epochs=args.epochs,\n",
        "            batch_size=args.batch,\n",
        "            img_size=args.img_size,\n",
        "            project_name=args.name,\n",
        "            resume=args.resume,\n",
        "            save_dir=args.save_dir,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tG2AbMduyZsX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}